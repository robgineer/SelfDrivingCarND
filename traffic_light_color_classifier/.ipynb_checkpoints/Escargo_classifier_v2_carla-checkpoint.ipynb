{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escargo Traffic Light Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training new classifier based on SqueezeNet approach \n",
    "https://github.com/DeepScale/SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "from random import randint\n",
    "import math\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras.models import load_model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Input, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Lambda, concatenate, ELU\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset, only consider traffic light colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train images, overall amount of images: 0\n"
     ]
    }
   ],
   "source": [
    "image_types = [\"red\", \"green\", \"yellow\"]\n",
    "input_img_x = 32\n",
    "input_img_y = 32\n",
    "\n",
    "full_set = []\n",
    "for im_type in image_types:\n",
    "    for ex in glob.glob(os.path.join(\"carla/\", im_type, \"*\")):\n",
    "        im = cv2.imread(ex)\n",
    "        if not im is None:\n",
    "            # Resize image to defined height and width\n",
    "            im = cv2.resize(im, (input_img_x, input_img_y))\n",
    "            # Convert to RGB...cv2 import is BGR\n",
    "            im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB) \n",
    "            # One hot encode the classes\n",
    "            one_hot_array = [0] * len(image_types)\n",
    "            one_hot_array[image_types.index(im_type)] = 1\n",
    "            # Check shape\n",
    "            assert(im.shape == (input_img_x, input_img_y, 3))\n",
    "            full_set.append((im, one_hot_array, ex))\n",
    "\n",
    "# Shuffle the data\n",
    "random.shuffle(full_set)\n",
    "print(\"Loaded train images, overall amount of images: {}\".format(len(full_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-78ee7b4e57a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "plt.imshow(full_set[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define split and batch size\n",
    "train_test_split_ratio = 0.9\n",
    "batch_size = 32\n",
    "\n",
    "# Split data into a training and test \n",
    "split_index = int(math.floor(len(full_set) * train_test_split_ratio))\n",
    "train_set = full_set[:split_index]\n",
    "test_set = full_set[split_index:]\n",
    "\n",
    "# Ensure data length can be divided by batch size\n",
    "train_set_offset = len(train_set) % batch_size\n",
    "test_set_offset = len(test_set) % batch_size\n",
    "# Cut off offset\n",
    "train_set = train_set[: len(train_set) - train_set_offset]\n",
    "test_set = test_set[: len(test_set) - test_set_offset]\n",
    "# Split\n",
    "train_x, train_y, train_z = zip(*train_set)\n",
    "test_x, test_y, test_z = zip(*test_set)\n",
    "# Convert to numpy array\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)\n",
    "print(\"Training samples: {}\".format(len(train_y)))\n",
    "print(\"Test samples: {}\".format(len(test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Example image:\")\n",
    "plt.imshow(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_class_weights(y):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    majority = max(counts)\n",
    "    return  {cls: float(majority/count) for cls, count in zip(unique, counts)}\n",
    "\n",
    "train_y_dec = np.argmax(train_y, axis=1)\n",
    "class_weights = get_class_weights(train_y_dec)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_rate = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fire_module(x, fire_id, squeeze=16, expand=64): \n",
    "    # Squeeze part with 1x1 conv\n",
    "    x = Conv2D(squeeze, (1, 1), padding='valid', name='fire' + str(fire_id) + '/' + \"squeeze1x1\")(x)\n",
    "    x = Activation('elu', name='fire' + str(fire_id) + '/elu_squeeze1x1')(x)\n",
    "    # Expand part with 1x1 conv\n",
    "    left = Conv2D(expand, (1, 1), padding='valid', name='fire' + str(fire_id) + '/' + \"expand1x1\")(x)\n",
    "    left = Activation('elu', name='fire' + str(fire_id) + '/elu_expand1x1')(left)\n",
    "    # Expand part with 3x3 conv\n",
    "    right = Conv2D(expand, (3, 3), padding='same', name='fire' + str(fire_id) + '/' + \"expand3x3\")(x)\n",
    "    right = Activation('elu', name='fire' + str(fire_id) + '/elu_expand3x3')(right)\n",
    "    # Fuse left and right expansion together\n",
    "    x = concatenate([left, right], axis=3, name='fire' + str(fire_id) + '/' + 'concat')\n",
    "    return x\n",
    "\n",
    "def squeeze_model():\n",
    "\n",
    "    input_img = Input(shape=(32, 32, 3))\n",
    "    \n",
    "    # Normalization from 0 to 1\n",
    "    x = Lambda(lambda x: x/255.0, input_shape=(32, 32, 3))(input_img)\n",
    "    \n",
    "    # Use two fire modules with 16 filter squeeze and 64 filter expand\n",
    "    x = fire_module(x, fire_id=1, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    # Use two fire modules with 32 filter squeeze and 128 filter expand\n",
    "    x = fire_module(x, fire_id=3, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    # Use two fire modules with 48 filter squeeze and 192 filter expand\n",
    "    x = fire_module(x, fire_id=5, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    # Dropout with drop rate\n",
    "    x = Dropout(drop_rate)(x)  \n",
    "    \n",
    "    # Last conv layer\n",
    "    x = Conv2D(100, (1, 1), padding='valid')(x)\n",
    "    x = Activation('elu')(x)\n",
    "    \n",
    "    # Global average pooling\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Output layer for the three classes with softmax\n",
    "    out = Dense(3, name='loss', activation=\"softmax\")(x)\n",
    "    \n",
    "    # Build model\n",
    "    model = Model(inputs=input_img, outputs=[out])     \n",
    "    return model\n",
    "\n",
    "# Summarize the model\n",
    "model = squeeze_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 35\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for checkpoints, visualisation and early stop\n",
    "check_point = ModelCheckpoint('./checkpoints/model-e{epoch:03d}.h5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto')\n",
    "# Early stop helps to prevent overfitting by stopping the training early in case that there is no chance anymore\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=4, verbose=0, mode='min')\n",
    "        \n",
    "history = model.fit(x=train_x,y=train_y,verbose=2,batch_size=batch_size,epochs=epochs,\n",
    "                    validation_data = (test_x, test_y), callbacks=[early_stop, check_point])\n",
    "\n",
    "model.save_weights('./model/model_carla.h5')\n",
    "print(\"...Done! Model trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize accuracies andlosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'bo')\n",
    "plt.plot(epochs, val_acc, 'b')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo')\n",
    "plt.plot(epochs, val_loss, 'b')\n",
    "plt.title('Training and validation loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the saved weights into a new model with same architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K.set_learning_phase(0)\n",
    "model2 = squeeze_model()\n",
    "model2.load_weights(\"./model/model_carla.h5\")\n",
    "print(\"New SqueezeNet model with saved weights loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    pred_ = list(model2.predict(image, verbose=0)[0])\n",
    "    pred_idx = pred_.index(max(pred_))\n",
    "    predicted_label = image_types[pred_idx]\n",
    "    return predicted_label\n",
    "\n",
    "idx_ = randint(0, len(test_x))\n",
    "image = test_x[idx_]\n",
    "plt.imshow(image)\n",
    "img = np.reshape(image, (1, 32, 32, 3))\n",
    "print(\"Predicted traffic light color: {}\".format(predict(img)))\n",
    "print(\"Original traffic light color: {}\".format(image_types[np.argmax(test_y[idx_])]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_img_x = 32\n",
    "input_img_y = 32\n",
    "\n",
    "test_set = []\n",
    "\n",
    "for ex in glob.glob(os.path.join(\"./test_images_carla\", \"*\")):\n",
    "    im = cv2.imread(ex)\n",
    "    if not im is None:\n",
    "        im = cv2.resize(im, (input_img_x, input_img_y))\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB) \n",
    "        test_set.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for img in test_set:\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    img = np.reshape(img, (1, 32, 32, 3))\n",
    "    pred = predict(img)\n",
    "    print(\"Prediction: {}\".format(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the saved keras model with weights into a tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = [None]\n",
    "pred_node_names = [None]\n",
    "pred_node_names[0] = 'output_'+str(0)\n",
    "pred[0] = tf.identity(model.output[0], name=pred_node_names[0])\n",
    "sess = K.get_session()\n",
    "constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)\n",
    "# Output the model as Tensorflow graph\n",
    "graph_io.write_graph(constant_graph, 'model', 'model_classification_carla.pb', as_text=False)\n",
    "print('Keras model converted to TensorFlow model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to load a graph from a protobuf file\n",
    "def load_graph(graph_file):\n",
    "    with tf.Session(graph=tf.Graph(), config=config) as sess:\n",
    "        gd = tf.GraphDef()\n",
    "        with tf.gfile.Open(graph_file, 'rb') as f:\n",
    "            data = f.read()\n",
    "            gd.ParseFromString(data)\n",
    "        tf.import_graph_def(gd, name='')\n",
    "        return sess.graph\n",
    "\n",
    "# Optimizations for Tensorflow (from tutorial)\n",
    "config = tf.ConfigProto()\n",
    "jit_level = tf.OptimizerOptions.ON_1\n",
    "config.graph_options.optimizer_options.global_jit_level = jit_level    \n",
    "\n",
    "# Load graph\n",
    "graph = load_graph(os.path.join('model', 'model_classification_carla.pb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get input and output tensors\n",
    "in_graph = graph.get_tensor_by_name('input_5:0')\n",
    "out_graph = graph.get_tensor_by_name('output_0:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pick a random image from the test set\n",
    "image = test_x[randint(0, len(test_x))]\n",
    "plt.imshow(image)\n",
    "\n",
    "# Do the prediction here\n",
    "with tf.Session(graph=graph, config=config) as sess:   \n",
    "    sfmax = list(sess.run(tf.nn.softmax(out_graph.eval(feed_dict={in_graph: [image]}))))\n",
    "    sf_ind = sfmax.index(max(sfmax))\n",
    "    predicted_label = image_types[sf_ind]\n",
    "    print(predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check it on the created test set again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for img in test_set:\n",
    "    with tf.Session(graph=graph, config=config) as sess:   \n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        pred_ = list(sess.run(tf.nn.softmax(out_graph.eval(feed_dict={in_graph: [img]}))))\n",
    "        pred_idx = pred_.index(max(pred_))\n",
    "        predicted_label = image_types[pred_idx]\n",
    "        print(\"Predicted traffic light by tensorflow graph: {}\".format(predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
